from collections import OrderedDict
from typing import List, Dict
from debug import draw_tree
import numpy as np
from rtree import index
import time


from bucket import *
from train_utils import *


p = index.Property()

p.dimension = 14

global_buckets_rtree = index.Index(properties=p)

global_queries_rtree = index.Index(properties=p)

global_buckets_dict = dict()

identifier = 0


def find_parent(query, root) -> Bucket:
    for child in root.children.values():
        if are_contain(child, query):
            return find_parent(query, child)
        elif not are_disjoint(child, query):
            return root
    return root


def deduplicate(buckets):
    buckets.sort(key=lambda x: x.mins+x.maxs)
    previous_bucket = buckets[0]
    unique_buckets = [previous_bucket]
    for current_bucket in buckets:
        if not are_coincide(previous_bucket, current_bucket):
            unique_buckets.append(current_bucket)
            previous_bucket = current_bucket
    return unique_buckets


def intersect_with_children(root: Bucket, query: Bucket):
    # 输入一个query_bucket,输出和其相交的所有的bucket
    coordinates = query.mins+query.maxs
    contains = set(root.rtree.contains(coordinates))  # query包含的bucket
    intersections = set(root.rtree.intersection(coordinates))
    overlaps = intersections-contains
    return overlaps, contains


def feed_a_overlap(query: Bucket, root: Bucket):
    global global_buckets_rtree, global_buckets_dict
    parent = find_parent(query, root)
    if are_coincide(parent, query):
        return parent
    overlaps, contains = intersect_with_children(parent, query)
    # parent中没有和这个查询相交或者包含的，则将这个bucket作为parent的孩子节点
    if len(overlaps) == 0 and len(contains) == 0:
        add_global_bucket(query)
        parent.add_for_overlap(query)
        if is_close_to_zero(parent.volume):
            merge_bucket_with_parent(parent)
        return query

    # 处理contains,即query包含的一些bucket,如有必要，需要将这些bucket作为query的孩子，并且从parent中移除这些bucket
    # overlap contain的bucket不会被query分割，应该也不会被处理（？）为了避免可能的重复操作，还是更新feature_id
    cur_contains = []
    for cid in contains:
        bucket = parent.children[cid]
        cur_contains.append(bucket)

    query.add_for_query(cur_contains, global_buckets_rtree, global_buckets_dict)
    if is_close_to_zero(query.volume):  # 如果这些包含的bucket恰好可以组成query,则不添加query
        return query

    # S4:处理和query相交的bucket
    tmp_rtree = index.Index(properties=p)
    tmp_overlap_buckets = []
    for oid in overlaps:
        bucket = parent.children[oid]
        if are_disjoint(bucket, query):  # rtree实现的overlap似乎和我们的overlap有歧义，仅仅边相交的，我们不当作overlap
            continue
        overlap = get_overlap(query, bucket)  # 相交区域
        tmp_overlap_buckets.append((oid, (overlap, bucket)))
        tmp_rtree.insert(oid, overlap.coordinates)

    overlaps_sorted = OrderedDict(sorted(tmp_overlap_buckets, key=lambda x: x[1][0].volume))
    valid_overlaps = []
    while overlaps_sorted:
        oid, (overlap, bucket) = overlaps_sorted.popitem()
        valid_overlaps.append((overlap, bucket))
        this_contains = list(tmp_rtree.contains(overlap.coordinates))
        for id in this_contains:
            (doverlap, dbucket) = overlaps_sorted.pop(id)
            tmp_rtree.delete(id, doverlap.coordinates)
    composed = []
    for overlap, bucket in valid_overlaps:
        ret = feed_a_overlap(overlap, bucket)
        if isinstance(ret, list):
            composed += ret
        else:
            composed.append(ret)
    if composed:
        query.add_for_query(composed, global_buckets_rtree, global_buckets_dict)
        if is_close_to_zero(query.volume):
            return cur_contains+composed

    parent.delete_contains(contains, cur_contains)
    add_global_bucket(query)
    parent.add_for_overlap(query)
    if is_close_to_zero(parent.volume):
        merge_bucket_with_parent(parent)
    return query


def add_global_bucket(bucket):
    global global_buckets_dict, global_buckets_rtree, identifier
    global_buckets_rtree.insert(identifier, bucket.coordinates)
    global_buckets_dict[identifier] = bucket
    identifier += 1


def feed_a_query(query: Bucket, root: Bucket):
    global global_buckets_rtree, global_buckets_dict
    parent = find_parent(query, root)  # 找到某个Bucket,其包含query,但其字节的不包含query
    # S1:query和当前直方图中某个Bucket重合
    if are_coincide(parent, query):
        #parent.cover_card = query.card
        query = parent  # 定位这个bucket
        return
    overlaps, contains = intersect_with_children(
        parent, query)  # 从parent中找到其直接overlap和contain的Bucket的rid

    # S2:parent中没有和这个查询相交或者包含的，则将这个bucket作为parent的孩子节点
    if len(overlaps) == 0 and len(contains) == 0:
        add_global_bucket(query)
        parent.add_for_overlap(query)
        if is_close_to_zero(parent.volume):
            merge_bucket_with_parent(parent)
        return

    # S3:处理被query包含的bucket，将这些bucket作为query的孩子，将其从parent中去除
    cur_contains = []
    for cid in contains:
        bucket = parent.children[cid]
        cur_contains.append(bucket)

    query.add_for_query(cur_contains, global_buckets_rtree, global_buckets_dict)
    if is_close_to_zero(query.volume):  # 如果这些包含的bucket恰好可以组成query,则不添加query
        return

    # S4:处理和query相交的bucket
    tmp_rtree = index.Index(properties=p)
    tmp_overlap_buckets = []
    for oid in overlaps:
        bucket = parent.children[oid]
        if are_disjoint(bucket, query):  # rtree实现的overlap似乎和我们的overlap有歧义，仅仅边相交的，我们不当作overlap
            continue
        overlap = get_overlap(query, bucket)  # 相交区域
        tmp_overlap_buckets.append((oid, (overlap, bucket)))
        tmp_rtree.insert(oid, overlap.coordinates)

    overlaps_sorted = OrderedDict(sorted(tmp_overlap_buckets, key=lambda x: x[1][0].volume))
    valid_overlaps = []
    while overlaps_sorted:
        oid, (overlap, bucket) = overlaps_sorted.popitem()
        valid_overlaps.append((overlap, bucket))
        this_contains = list(tmp_rtree.contains(overlap.coordinates))
        for id in this_contains:
            if id != oid:
                (doverlap, dbucket) = overlaps_sorted.pop(id)
                tmp_rtree.delete(id, doverlap.coordinates)
    composed = []
    for overlap, bucket in valid_overlaps:
        ret = feed_a_overlap(overlap, bucket)
        if isinstance(ret, list):
            composed += ret
        else:
            composed.append(ret)
    query.add_for_query(composed, global_buckets_rtree, global_buckets_dict)
    if is_close_to_zero(query.volume):
        return

    # 最终overlaps和contains都没有填充query，则将query添加为parent的孩子，并将parent中被query包含的孩子转换为query的孩子
    parent.delete_contains(contains, cur_contains)
    add_global_bucket(query)
    parent.add_for_overlap(query)
    if is_close_to_zero(parent.volume):
        merge_bucket_with_parent(parent)
    return


def merge_bucket_with_parent(bucket: Bucket):
    """当该某个Bucket由他的孩子Bucket全部填充,则删除这个Bucket,并将其孩子节点添加到其父节点中
    Args:
        bucket (Bucket):要被merge的节点
    """
    if bucket.parents:  # 如果没有父节点则跳过（root）
        # 删除其孩子节点的父节点中有关bucket的信息
        for child in bucket.children:
            del child.parents[bucket]

        # 将其孩子节点添加到bucket的父节点中
        for parent, bid in bucket.parents.items():
            parent.merge_update(bid, bucket)



def gen_global_rtree(buckets: List[Bucket]):
    for i, bucket in enumerate(buckets):
        global_queries_rtree.insert(i, bucket.coordinates)


def gen_query_buckets(queries):
    buckets = [Bucket(q.mins, q.maxs, q.card)for q in queries]
    unique_buckets = deduplicate(buckets)
    unique_buckets.sort(key=lambda x: x.density)
    return unique_buckets


def construct_histogram(queries, mins, maxs, num_tuples):
    print("Start Generate the Histogram...")
    p.dimension = len(queries[0].mins)
    root_bucket = Bucket(mins, maxs, num_tuples)
    start = time.time()
    input_buckets = gen_query_buckets(queries)
    gen_global_rtree(input_buckets)
    num_buckets = len(input_buckets)
    for i, bucket in enumerate(input_buckets):
        print(f"Construct Histogram Step [{i+1}/{num_buckets}]")
        feed_a_query(bucket, root_bucket)
    end = time.time()
    print("Generate Hisogram Time Cost:{}".format(end-start))
    return root_bucket


def test():
    queries = [Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]),
               Bucket(mins=[0.3, 0.65], maxs=[0.5, 0.7]),
               Bucket(mins=[0.3, 0.5], maxs=[0.5, 0.8]),
               Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]), ]

    queries = [
        Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6], card=100),
        Bucket(mins=[0.3, 0.3], maxs=[0.8, 0.8], card=150),
        Bucket(mins=[0.7, 0.1], maxs=[0.8, 0.8], card=200),
        Bucket(mins=[0.3, 0.2], maxs=[0.6, 0.8], card=250),
        # Bucket(mins=[0.3, 0.2], maxs=[0.6, 0.8]),
        # Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]),
        # Bucket(mins=[0.1, 0.65], maxs=[0.5, 0.7]),
    ]
    hist = construct_histogram(queries, [0, 0], [1, 1], 1000)

    for i, c in enumerate(hist.children.values()):
        print("num", i)
        draw_tree(c, i)
    draw_tree(hist, 100)
    return hist


#test()
######################
from collections import OrderedDict, deque
from typing import List, Dict
from debug import draw_tree
import numpy as np
from rtree import index
import time


from bucket import *
from train_utils import *


p = index.Property()

p.dimension = 14

global_buckets_rtree = index.Index(properties=p)

global_queries_rtree = index.Index(properties=p)

global_buckets_dict = dict()

identifier = 1

feature_id = 0


def find_parent(query: Bucket, root: Bucket) -> Bucket:
    global feature_id
    visited_able = set()  # 包含query的遍历集合
    visited_unable = set()  # 不包含query的遍历集合
    queue = deque([root.identifier])
    while queue:
        node = queue.popleft()
        target = True
        node_item = global_buckets_dict[node]
        node_item.feature_father = feature_id
        for cid in node_item.children:
            if cid in visited_able:  # 已经遍历过，且包含query
                target = False
                continue
            elif cid in visited_unable:  # 已经遍历过，但包含query
                continue
            else:  # 没有遍历过
                c_node_item = global_buckets_dict[cid]
                if are_contain(c_node_item, query):  # 包含query
                    target = False
                    queue.append(cid)
                    visited_able.add(cid)
                else:  # 不包含query
                    visited_unable.add(cid)
        if target:  # 该节点的孩子节点都不包含query,则该节点是包含query的最小节点
            target_node = node_item
    return target_node


def deduplicate(buckets):
    buckets.sort(key=lambda x: x.mins+x.maxs)
    previous_bucket = buckets[0]
    unique_buckets = [previous_bucket]
    for current_bucket in buckets:
        if not are_coincide(previous_bucket, current_bucket):
            unique_buckets.append(current_bucket)
            previous_bucket = current_bucket
    return unique_buckets


def intersect_with_children(root: Bucket, query: Bucket):
    # print("intersect_with_children")
    # 输入一个query_bucket,输出和其相交的所有的bucket
    global global_buckets_dict
    coordinates = query.coordinates
    contains = set(root.rtree.contains(coordinates)
                   ) & root.children  # query包含的bucket
    intersections = set(root.rtree.intersection(coordinates)) & root.children
    overlaps = intersections-contains
    valid_overlaps = []
    for oid in overlaps:
        bucket = global_buckets_dict[oid]
        if are_disjoint(bucket, query):  # rtree实现的overlap似乎和我们的overlap有歧义，仅仅边相交的，我们不当作overlap
            continue
        valid_overlaps.append(oid)
    return set(valid_overlaps), contains


def add_global_bucket(bucket: Bucket):
    # print("add_global_bucket")
    global global_buckets_dict, global_buckets_rtree, identifier
    global_buckets_rtree.insert(identifier, bucket.coordinates)
    global_buckets_dict[identifier] = bucket
    bucket.identifier = identifier
    identifier += 1


def delete_global_bucket(bucket: Bucket):
    # print("delete_global_bucket")
    global global_buckets_dict, global_buckets_rtree, identifier
    global_buckets_rtree.delete(bucket.identifier, bucket.coordinates)
    del global_buckets_dict[bucket.identifier]


def cacl_valid_overlap(overlaps, query):
    global global_buckets_dict
    tmp_rtree = index.Index(properties=p)
    tmp_overlap_buckets = []
    for oid in overlaps:
        bucket = global_buckets_dict[oid]
        overlap = get_overlap(query, bucket)  # 相交区域
        tmp_overlap_buckets.append((oid, (overlap, bucket)))
        tmp_rtree.insert(oid, overlap.coordinates)

    overlaps_sorted = OrderedDict(
        sorted(tmp_overlap_buckets, key=lambda x: x[1][0].volume))
    valid_overlaps = []
    while overlaps_sorted:
        oid, (overlap, bucket) = overlaps_sorted.popitem()
        valid_overlaps.append((overlap, bucket))
        this_contains = list(tmp_rtree.contains(overlap.coordinates))
        for id in this_contains:
            if id != oid:
                (doverlap, dbucket) = overlaps_sorted.pop(id)
                tmp_rtree.delete(id, doverlap.coordinates)


def feed_a_query(query: Bucket, root: Bucket):
    global global_buckets_rtree, global_buckets_dict, feature_id
    parent = find_parent(query, root)

    if are_coincide(parent, query):
        query = parent
        coordinates = query.coordinates
        for cid in query.children:  # 标记child
            child = global_buckets_dict[cid]
            child.feature_cover = feature_id
        for q_parent in query.parents:
            if are_contain(root, parent):
                intersections = set(q_parent.rtree.intersection(
                    coordinates)) & q_parent.children-{query.identifier}
                for id in intersections:
                    bucket = global_buckets_dict[id]
                    bucket.feature_father = feature_id
        return query

    overlaps, contains = intersect_with_children(parent, query)

    # parent中的孩子节点没有和query相交或者被包含的，则将这个bucket作为parent的孩子节点
    if len(overlaps) == 0 and len(contains) == 0:
        add_global_bucket(query)  # 添加全局Bucket
        parent.add_for_overlap(query)
        if is_close_to_zero(parent.volume):
            merge_bucket_with_parent(parent)
        return query

    # 处理contains,即query包含的一些bucket,如有必要，需要将这些bucket作为query的孩子，并且从parent中移除这些bucket
    # overlap contain的bucket不会被query分割，应该也不会被处理（？）为了避免可能的重复操作，还是更新feature_id
    # 根据feature_id
    contains_buckets = []
    for cid in contains:
        bucket = parent.children[cid]
        contains_buckets.append(bucket)
    query.add_for_contain(
        contains_buckets, global_buckets_rtree, global_buckets_dict)
    if is_close_to_zero(query.volume):  # 如果这些包含的bucket恰好可以组成query,则不添加query
        return contains_buckets
    else:
        parent.delete_contains(contains_buckets)

    # 预处理overlap:
    overlap_contains_buckets = set()
    overlaps_to_remove = set()
    for oid in overlaps:
        bucket = global_buckets_dict[oid]
        if bucket.feature_father == feature_id:  # 该overlap已经被处理过
            for cid in bucket.children:
                child = global_buckets_dict[cid]
                if child.feature_cover == feature_id:
                    query.add_for_query()

    # S4:处理和query相交的bucket
    # 有效的overlap_bucket:
    # 1.和query相交但不包含query且不被query包含
    # 2.产生的overlap区域不被其他overlap包含
    # 3.可以覆盖query的最小集合
    valid_overlaps = cacl_valid_overlap(overlaps, query)

    composed = []
    for overlap, bucket in valid_overlaps:
        ret = feed_a_query(overlap, bucket)
        bucket.featured_children = ret
        if isinstance(ret, list):
            composed += ret
        else:
            composed.append(ret)
        query.add_for_query(ret, global_buckets_rtree,
                            global_buckets_dict)
        if is_close_to_zero(query.volume):
            return contains_buckets+composed

    add_global_bucket(query)
    parent.add_for_overlap(query)
    if is_close_to_zero(parent.volume):
        merge_bucket_with_parent(parent)
    return query


def merge_bucket_with_parent(bucket: Bucket):
    """当该某个Bucket由他的孩子Bucket全部填充,则删除这个Bucket,并将其孩子节点添加到其父节点中
    Args:
        bucket (Bucket):要被merge的节点
    """
    if bucket.identifier == 0:
        return
    delete_global_bucket(bucket)
    # 删除其孩子节点的父节点中有关bucket的信息
    for cid in bucket.children:
        child = global_buckets_dict[cid]
        child.parents.remove(bucket)

    # 将其孩子节点添加到bucket的父节点中
    for parent in bucket.parents:
        parent.merge_update(bucket, global_buckets_dict)


def gen_global_rtree(buckets: List[Bucket]):
    for i, bucket in enumerate(buckets):
        global_queries_rtree.insert(i, bucket.coordinates)


def gen_query_buckets(queries):
    buckets = [Bucket(q.mins, q.maxs, q.card)for q in queries]
    unique_buckets = deduplicate(buckets)
    unique_buckets.sort(key=lambda x: x.density)
    return unique_buckets


def construct_histogram(queries, mins, maxs, num_tuples):
    # print("Start Generate the Histogram...")
    global feature_id
    p.dimension = len(queries[0].mins)
    root_bucket = Bucket(mins, maxs, num_tuples)
    start = time.time()
    input_buckets = gen_query_buckets(queries)
    gen_global_rtree(input_buckets)
    num_buckets = len(input_buckets)
    for i, bucket in enumerate(input_buckets):
        print(f"Construct Histogram Step [{i+1}/{num_buckets}]")
        feed_a_query(bucket, root_bucket)
        feature_id = i
    end = time.time()
    print("Generate Hisogram Time Cost:{}".format(end-start))
    return root_bucket


def test():
    queries = [Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]),
               Bucket(mins=[0.3, 0.65], maxs=[0.5, 0.7]),
               Bucket(mins=[0.3, 0.5], maxs=[0.5, 0.8]),
               Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]), ]

    queries = [
        Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6], card=100),
        Bucket(mins=[0.3, 0.3], maxs=[0.8, 0.8], card=150),
        Bucket(mins=[0.7, 0.1], maxs=[0.8, 0.8], card=200),
        Bucket(mins=[0.3, 0.2], maxs=[0.6, 0.8], card=250),
        # Bucket(mins=[0.3, 0.2], maxs=[0.6, 0.8]),
        # Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]),
        # Bucket(mins=[0.1, 0.65], maxs=[0.5, 0.7]),
    ]
    hist = construct_histogram(queries, [0, 0], [1, 1], 1000)

    for i, c in enumerate(hist.children):
        # print("num", i)
        draw_tree(c, i)
    draw_tree(hist, 100)
    return hist


test()

##############
from collections import OrderedDict, deque
from typing import List, Dict
from debug import draw_tree
import numpy as np
from rtree import index
import time
from line_profiler import LineProfiler

from bucket import *
from train_utils import *


p = index.Property()
p.dimension = 14
global_buckets_rtree = index.Index(properties=p)

global_queries_rtree = index.Index(properties=p)

global_buckets_dict = dict()

identifier = 1


def deduplicate(buckets):
    buckets.sort(key=lambda x: x.mins+x.maxs)
    previous_bucket = buckets[0]
    unique_buckets = [previous_bucket]
    for current_bucket in buckets:
        if not are_coincide(previous_bucket, current_bucket):
            unique_buckets.append(current_bucket)
            previous_bucket = current_bucket
    return unique_buckets


def gen_global_rtree(buckets: List[Bucket]):
    for i, bucket in enumerate(buckets):
        global_queries_rtree.insert(i, bucket.coordinates)


#@profile
def add_global_bucket(bucket: Bucket):
    # print("add_global_bucket")
    global global_buckets_dict, global_buckets_rtree, identifier
    #global_buckets_rtree.insert(identifier, bucket.coordinates)
    global_buckets_dict[identifier] = bucket
    bucket.identifier = identifier
    bucket.composed.add(identifier)
    identifier += 1


def delete_global_bucket(bucket: Bucket):
    print("delete_global_bucket")
    #global global_buckets_dict, global_buckets_rtree, identifier
    global_buckets_rtree.delete(bucket.identifier, bucket.coordinates)
    del global_buckets_dict[bucket.identifier]


def gen_query_buckets(queries):
    buckets = [Bucket(q.mins, q.maxs, q.card)for q in queries]
    unique_buckets = deduplicate(buckets)
    unique_buckets.sort(key=lambda x: x.density)
    return unique_buckets


def find_small_parent(query: Bucket, root: Bucket):
    stack = deque([root])
    while stack:
        node = stack.pop()
        target = True
        for id in node.children:
            bucket = global_buckets_dict[id]
            if are_contain(bucket, query):
                stack.append(bucket)
                target = False
                break
        if target:
            return node


def ids_2_buckets(ids):
    return set([global_buckets_dict[id] for id in ids])


def sum_volume(buckets):
    return np.sum([bucket.volume for bucket in buckets])




#@profile
def feed_a_query_naive(query: Bucket, root: Bucket, overlaps: set, input_visited: set, root_query_contain_ids: set):
    best_parent = True
    overlap_containers = []
    query_contain_child_buckets = set()
    query_contain_compose_ids = set()
    for id in root.children.copy():
        bucket = global_buckets_dict[id]
        if id in overlaps:  # 和query相交
            if id in input_visited:  # 已经被查过,在root的parent中的其他child被检查
                if are_coincide(query, bucket.overlap_with_query.data):  # query已经被包含过
                    best_parent = False
                    cret_dataset = bucket.overlap_with_query.dataset
                    cret_composed = bucket.overlap_with_query.composed_set
                else:
                    overlap_containers.append(bucket.overlap_with_query)
            else:  # 未被查过
                if are_contain(bucket, query):  # bucket包含query
                    best_parent = False
                    bucket.overlap_with_query = root.overlap_with_query
                    cret_dataset, cret_composed = feed_a_query_naive(
                        query, bucket, overlaps, input_visited, root_query_contain_ids)
                    bucket.overlap_with_query.dataset = cret_dataset
                    bucket.overlap_with_query.composed_set = cret_composed
                else:  # bucket不包含query
                    new_overlap = get_overlap(query, bucket)
                    bucket.overlap_with_query = Container()
                    bucket.overlap_with_query.data = new_overlap
                    oret_dataset, oret_composed = feed_a_query_naive(
                        new_overlap, bucket, overlaps, input_visited, root_query_contain_ids)
                    bucket.overlap_with_query.dataset = oret_dataset
                    bucket.overlap_with_query.composed_set = oret_composed
                    overlap_containers.append(bucket.overlap_with_query)
                input_visited.add(id)
        elif id in root_query_contain_ids:
            query_contain_child_buckets.add(bucket)
        else:#可能远离，相交，或者包含
            if not are_disjoint(bucket,query):#
                if are_contain(query,bucket):
                    query_contain_child_buckets.add(bucket)
                    root_query_contain_ids |= bucket.composed
                else:
                    overlaps.add(id)
                    if id in input_visited:  # 已经被查过,在root的parent中的其他child被检查
                        if are_coincide(query, bucket.overlap_with_query.data):  # query已经被包含过
                            best_parent = False
                            cret_dataset = bucket.overlap_with_query.dataset
                            cret_composed = bucket.overlap_with_query.composed_set
                        else:
                            overlap_containers.append(bucket.overlap_with_query)
                    else:  # 未被查过
                        if are_contain(bucket, query):  # bucket包含query
                            best_parent = False
                            bucket.overlap_with_query = root.overlap_with_query
                            cret_dataset, cret_composed = feed_a_query_naive(
                                query, bucket, overlaps, input_visited, root_query_contain_ids)
                            bucket.overlap_with_query.dataset = cret_dataset
                            bucket.overlap_with_query.composed_set = cret_composed
                        else:  # bucket不包含query
                            new_overlap = get_overlap(query, bucket)
                            bucket.overlap_with_query = Container()
                            bucket.overlap_with_query.data = new_overlap
                            oret_dataset, oret_composed = feed_a_query_naive(
                                new_overlap, bucket, overlaps, input_visited, root_query_contain_ids)
                            bucket.overlap_with_query.dataset = oret_dataset
                            bucket.overlap_with_query.composed_set = oret_composed
                            overlap_containers.append(bucket.overlap_with_query)
                        input_visited.add(id)
    
    
    for bucket in query_contain_child_buckets:
        query_contain_compose_ids |= bucket.composed
    query_contain_compose_buckets = ids_2_buckets(query_contain_compose_ids)
    query_contain_child_volume = sum_volume(query_contain_compose_buckets)

    if are_floats_equal(query.volume, query_contain_child_volume):
        return query_contain_child_buckets, query_contain_compose_ids

    
    if best_parent:
        overlap_contain_compose_ids = set()
        overlap_contain_buckets = set()
        for item in overlap_containers:
            overlap_contain_compose_ids |= item.composed_set
            dataset = item.dataset
            if isinstance(dataset, set):
                overlap_contain_buckets |= dataset
            else:
                overlap_contain_buckets.add(dataset)
        query_compose_ids = overlap_contain_compose_ids | query_contain_compose_ids
        query_compose_buckets = ids_2_buckets(query_compose_ids)
        compose_volume = sum_volume(query_compose_buckets)

        valid_overlap_contain_buckets = cacl_valid_contains(overlap_contain_buckets, query_compose_ids)

        valid_contain_buckets = valid_overlap_contain_buckets | query_contain_child_buckets

        if are_floats_equal(compose_volume, query.volume):
            root.composed |= query_compose_ids
            return valid_overlap_contain_buckets, query_compose_ids
        else:
            add_global_bucket(query)
            query.composed |= query_compose_ids
            root.composed |= query.composed
            # 删除root的children中属于query的
            root.delete_contains(query_contain_child_buckets)
            # 向query中添加bucket
            for item in valid_contain_buckets:
                query._init_add(item)
            query.volume -= compose_volume
            root.add_for_overlap(query)
            """ if is_close_to_zero(root.volume):
                merge_bucket_with_parent(root) """
            return query, query.composed

    else:
        return cret_dataset, cret_composed


# #@profile


def find_overlap_with_query(query: Bucket, root: Bucket, overlaps: set, input_visited: set, query_contains: set):
    target = True  # 标记，指示root的孩子节点中是否有包含query的，若target=True，则root就是query的最小父节点，将query添加到root的孩子节点中
    overlap_containers = []  # 保存root中的child和query相交产生的孩子
    this_visited = set()  # 对于此root,标记此root中已经被计算cover面积的bucket

    # 计算contains
    query_contains_child_ids = root.children & query_contains

    query_contains_child_composed = set()  # 包含在query中的，root_child的composed
    for id in query_contains_child_ids:
        child = global_buckets_dict[id]
        query_contains_child_composed |= child.composed
    ids_to_buckets = [global_buckets_dict[id] for id in query_contains_child_composed]
    contains_child_cover_volume = np.sum([bucket.volume for bucket in ids_to_buckets])

    # cacl_delta_cover and composed
    c_delta_composed = query_contains_child_composed - input_visited
    c_delta_cover = np.sum([global_buckets_dict[id].volume for id in c_delta_composed])

    query_contains_child_buckets = set([global_buckets_dict[id] for id in query_contains_child_ids])

    if are_floats_equal(contains_child_cover_volume, query.volume):
        # 更新input_visited
        input_visited |= c_delta_composed
        return query_contains_child_buckets, c_delta_cover, c_delta_composed, query_contains_child_buckets
    this_visited = query_contains_child_composed

    for id in root.children.copy():
        if id in overlaps:  # 和query相交
            bucket = global_buckets_dict[id]
            if id in input_visited:  # 已经被查过,在root的parent中的其他child被检查
                if are_coincide(query, bucket.overlap_with_query.data):  # query已经被包含过
                    target = False
                    cret_dataset = bucket.overlap_with_query.dataset
                    cret_delta_cover = 0
                    cret_delta_composed = set()
                    cret_composed = bucket.overlap_with_query.composed_set
                else:
                    this_visited |= bucket.overlap_with_query.composed_set
                    bucket.overlap_with_query.delta_composed = bucket.overlap_with_query.composed_set - input_visited
                    bucket.overlap_with_query.delta_volume = np.sum(
                        [global_buckets_dict[i] for i in bucket.overlap_with_query.delta_composed])
                    overlap_containers.append(bucket.overlap_with_query)
            else:  # 未被查过
                if are_contain(bucket, query):  # bucket包含query
                    target = False
                    bucket.overlap_with_query = root.overlap_with_query
                    cret_dataset, cret_delta_cover, cret_delta_composed, cret_composed = find_overlap_with_query(
                        query, bucket, overlaps, this_visited, query_contains)
                    bucket.overlap_with_query.dataset = cret_dataset
                    bucket.overlap_with_query.delta_cover = cret_delta_cover
                    bucket.overlap_with_query.delta_composed = cret_delta_composed
                    bucket.overlap_with_query.composed_set = cret_composed
                else:  # bucket不包含query
                    new_overlap = get_overlap(query, bucket)
                    bucket.overlap_with_query = Container()
                    bucket.overlap_with_query.data = new_overlap
                    oret_dataset, oret_delta_cover, oret_delta_composed, oret_composed = find_overlap_with_query(
                        new_overlap, bucket, overlaps, this_visited, query_contains)
                    bucket.overlap_with_query.dataset = oret_dataset
                    bucket.overlap_with_query.delta_cover = oret_delta_cover
                    bucket.overlap_with_query.delta_composed = oret_delta_composed
                    bucket.overlap_with_query.composed_set = oret_composed
                    overlap_containers.append(bucket.overlap_with_query)
                input_visited.add(id)
    if target:  # 其孩子节点均不包含input
        # 两个volume
        # 1.root剩余的volume:volume_1
        # 2.根据input_visited计算给parent增加的volume

        # 处理input_visited

        # 处理this_visited

        # 计算volume_1
        # step1:overlap_contains

        overlap_contain_buckets = set()
        overlap_cover_volume = 0
        new_query_composed_ids = set()
        for item in overlap_containers:
            overlap_cover_volume += item.delta_cover
            new_query_composed_ids |= item.delta_composed
            dataset = item.dataset
            if isinstance(dataset, set):
                overlap_contain_buckets |= dataset
            else:
                overlap_contain_buckets.add(dataset)
        query_contains |= new_query_composed_ids
        cover_volume = contains_child_cover_volume + overlap_cover_volume
        all_composed = new_query_composed_ids | query_contains_child_composed

        valid_overlap_contain_buckets = cacl_valid_contains(overlap_contain_buckets, all_composed)

        valid_contains = valid_overlap_contain_buckets | query_contains_child_buckets

        o_delta_composed = new_query_composed_ids - input_visited
        oc_delta_composed = o_delta_composed | c_delta_composed
        o_delta_cover = np.sum([global_buckets_dict[id].volume for id in o_delta_composed])
        oc_delta_cover = o_delta_cover+c_delta_cover

        if are_floats_equal(cover_volume, query.volume):
            input_visited |= oc_delta_composed
            query.composed |= all_composed
            root.composed |= query.composed
            return valid_contains, oc_delta_cover, oc_delta_composed, all_composed
        else:  # 添加
            add_global_bucket(query)
            query.composed |= all_composed
            root.composed |= query.composed
            # 删除root的children中属于query的
            root.delete_contains(query_contains_child_buckets)
            # 向query中添加bucket
            for item in valid_contains:
                query._init_add(item)
            query.volume -= cover_volume
            root.add_for_overlap(query)

            oc_delta_composed.add(query.identifier)
            oc_delta_cover += query.volume
            input_visited |= oc_delta_composed

            if is_close_to_zero(root.volume):
                merge_bucket_with_parent(root)

            return query, oc_delta_cover, oc_delta_composed, query.composed.copy()
    else:
        return cret_dataset, cret_delta_cover, cret_delta_composed, cret_composed


def cacl_valid_contains(overlap_contain_buckets: set, composed_ids: set):
    valid_contain_buckets = set()

    # 找到overlap_contain_buckets中合法的

    for bucket in overlap_contain_buckets:
        valid_flag = True
        for parent in bucket.parents:
            if parent.identifier in composed_ids:
                valid_flag = False
                break
        if valid_flag:
            valid_contain_buckets.add(bucket)
    return valid_contain_buckets


def merge_bucket_with_parent(bucket: Bucket):
    print("merge")
    """当该某个Bucket由他的孩子Bucket全部填充,则删除这个Bucket,并将其孩子节点添加到其父节点中
    Args:
        bucket (Bucket):要被merge的节点
    """
    if bucket.identifier == 0:
        return
    delete_global_bucket(bucket)
    # 删除其孩子节点的父节点中有关bucket的信息
    for cid in bucket.children:
        child = global_buckets_dict[cid]
        child.parents.remove(bucket)

    # 将其孩子节点添加到bucket的父节点中
    for parent in bucket.parents:
        parent.merge_update(bucket, global_buckets_dict)


#@profile
def check_cover(query: Bucket):
    query_contains = set(global_buckets_rtree.contains(query.coordinates))
    contains_volume = np.sum([global_buckets_dict[id].volume for id in query_contains])
    return query_contains, contains_volume


def get_overlaps_and_contains(parent, query):
    query_contains, contains_volume = check_cover(query)
    parent_contains = set(global_buckets_rtree.contains(
        parent.coordinates))
    intersections = set(
        global_buckets_rtree.intersection(query.coordinates))

    overlap_to_remove = set()

    overlaps = parent_contains & intersections - query_contains  # 和query相交的所有bucket

    for id in overlaps:
        bucket = global_buckets_dict[id]
        if are_disjoint(bucket, query):
            overlap_to_remove.add(id)
    overlaps -= overlap_to_remove
    return query_contains, overlaps


def get_overlaps_and_contains_naive(parent, query):
    contain_compose_ids = set()
    root_level_overlap_ids = set()
    for cid in parent.children:
        bucket = global_buckets_dict[cid]
        if are_contain(query, bucket):
            contain_compose_ids |= bucket.composed
        elif not are_disjoint(query, bucket):
            root_level_overlap_ids.add(cid)

    return contain_compose_ids, root_level_overlap_ids


#@profile
def feed_a_query_root(query: Bucket, root: Bucket):
    global global_buckets_rtree, global_buckets_dict

    parent = find_small_parent(query, root)  # 包含query的最小的bucket
    query_contains, overlaps = get_overlaps_and_contains_naive(parent, query)
    visited = set()
    feed_a_query_naive(query, parent, overlaps, visited, query_contains)
    #find_overlap_with_query(query, parent, overlaps,visited, query_contains)


def check_volume(hist):
    for cid in hist.children:
        bucket = global_buckets_dict[cid]
        check_volume(bucket)
        cbs = ids_2_buckets(bucket.composed)
        vol = sum_volume(cbs)
        if not are_floats_equal(vol,bucket.cover_volume):
            print("error 3")
        
        

def construct_histogram(queries, mins, maxs, num_tuples):
    print("Start Generate the Histogram...")
    global global_buckets_dict
    p.dimension = len(queries[0].mins)
    root_bucket = Bucket(mins, maxs, num_tuples)
    root_bucket.composed.add(0)
    global_buckets_dict[0] = root_bucket
    start = time.time()
    input_buckets = gen_query_buckets(queries)[:30]
    gen_global_rtree(input_buckets)
    num_buckets = len(input_buckets)
    for i, bucket in enumerate(input_buckets):
        print(f"Construct Histogram Step [{i+1}/{num_buckets}]")
        feed_a_query_root(bucket, root_bucket)
    end = time.time()
    print("Generate Hisogram Time Cost:{}".format(end-start))
    
    check_volume(root_bucket)
    for key, bucket in global_buckets_dict.items():
        if bucket.volume <= 0:
            print("volume error",bucket.volume)
    return root_bucket


def test():
    """ queries = [Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]),
               Bucket(mins=[0.3, 0.65], maxs=[0.5, 0.7]),
               Bucket(mins=[0.3, 0.5], maxs=[0.5, 0.8]),
               Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]), ] """

    """ queries = [
        Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6], card=100),
        Bucket(mins=[0.3, 0.3], maxs=[0.8, 0.8], card=150),
        Bucket(mins=[0.7, 0.1], maxs=[0.8, 0.8], card=200),
        Bucket(mins=[0.3, 0.2], maxs=[0.6, 0.8], card=250),
        # Bucket(mins=[0.3, 0.2], maxs=[0.6, 0.8]),
        # Bucket(mins=[0.1, 0.1], maxs=[0.6, 0.6]),
        # Bucket(mins=[0.1, 0.65], maxs=[0.5, 0.7]),
    ] """

    queries = [
        Bucket(mins=[0.1, 0.5], maxs=[0.6, 0.9], card=6),
        Bucket(mins=[0.4, 0.2], maxs=[0.9, 0.8], card=10),
        Bucket(mins=[0.2, 0.3], maxs=[0.7, 0.7], card=20),
    ]

    hist = construct_histogram(queries, [0, 0], [1, 1], 1000)

    print(global_buckets_dict.keys())

    """ for i, c in enumerate(hist.children):
        # print("num", i)
        draw_tree(c, i) """
    draw_tree(hist, 100, global_buckets_dict)
    return hist


#test()
